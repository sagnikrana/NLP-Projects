{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from utils import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = [\n",
    "  ('This article is awesome', 1),\n",
    "  ('There are just too much words here', 0), \n",
    "  ('The math is actually wrong here', 0),\n",
    "  ('I really enjoy learning new stuff', 1),\n",
    "  ('I am kinda lazy so I just skim these texts', 0),\n",
    "  ('Who cares about AI?', 0),\n",
    "  ('I will surely be a better person after reading this!', 1),\n",
    "  ('The author is pretty cute :)', 1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings():\n",
    "    \"\"\"\n",
    "    A class to read the word embedding file and to create the word embedding matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, vector_dimension):\n",
    "        self.path = path \n",
    "        self.vector_dimension = vector_dimension\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_coefs(word, *arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "    def get_embedding_index(self):\n",
    "        embeddings_index = dict(self.get_coefs(*o.split(\" \")) for o in open(self.path, errors='ignore'))\n",
    "        return embeddings_index\n",
    "\n",
    "    def create_embedding_matrix(self, tokenizer, max_features):\n",
    "        \"\"\"\n",
    "        A method to create the embedding matrix\n",
    "        \"\"\"\n",
    "        model_embed = self.get_embedding_index()\n",
    "\n",
    "        embedding_matrix = np.zeros((max_features + 1, self.vector_dimension))\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index > max_features:\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                    embedding_matrix[index] = model_embed[word]\n",
    "                except:\n",
    "                    continue\n",
    "        return embedding_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "create_embedding_matrix() missing 2 required positional arguments: 'tokenizer' and 'max_features'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-20a3cb5c05ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'embeddings/mini_embedding.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_dimension\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_embedding_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: create_embedding_matrix() missing 2 required positional arguments: 'tokenizer' and 'max_features'"
     ]
    }
   ],
   "source": [
    "embedding = Embeddings('embeddings/mini_embedding.txt', vector_dimension=2)\n",
    "embedding_matrix = embedding.create_embedding_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "training data  1  -  this article awesome *** label:  1\ntraining data  2  -  there are just too much words here *** label:  0\ntraining data  3  -  math actually wrong here *** label:  0\ntraining data  4  -  i really enjoy learning new stuff *** label:  1\ntraining data  5  -  i am kinda lazy so i just skim these texts *** label:  0\n"
     ]
    }
   ],
   "source": [
    "X_train = [x[0] for x in d] # Text\n",
    "Y_train = [y[1] for y in d] # Label\n",
    "X_train = [clean_text(x) for x in X_train]\n",
    "for i in range(5):\n",
    "    print(\"training data \", i+1,\" - \", X_train[i], \"*** label: \", Y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<torchnlp.encoders.text.static_tokenizer_encoder.StaticTokenizerEncoder object at 0x7fb462f5b5b0>\n"
     ]
    }
   ],
   "source": [
    "from torchnlp.encoders.text import StaticTokenizerEncoder, stack_and_pad_tensors, pad_tensor\n",
    "loaded_data = [\"now this ain't funny\", \"so don't you dare laugh\"]\n",
    "encoder = StaticTokenizerEncoder(loaded_data, tokenize=lambda s: s.split())\n",
    "encoded_data = [encoder.encode(example) for example in loaded_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}